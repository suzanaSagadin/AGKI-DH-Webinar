{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verkettung von Extraktion und Entitätenerkennung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Einrichtung der Modelle.\n",
    "2. Definition der Datenstruktur (Output).\n",
    "3. Vorbereitung von Beispielen und Anweisungen für die Modelle.\n",
    "4. Die Hauptaufgaben sind:\n",
    "    - Extrahieren von Statements: Aufteilung des historischen Textes in sinnvolle, zeitlich geordnete Aussagen.\n",
    "    - Durchführen von NER: Analyse jeder Aussage, um wichtige Entitäten wie Namen, Orte und Handlungen zu identifizieren.\n",
    "5. Kombination beider Aufgaben in einer Kette.\n",
    "6. Ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_together import ChatTogether\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables.base import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_TogehterAI_Llama3_8B = ChatTogether(\n",
    "    model=\"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "llm_TogehterAI_Llama3_70B_Lite = ChatTogether(\n",
    "    model=\"meta-llama/Meta-Llama-3-70B-Instruct-Lite\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEROutput(BaseModel):\n",
    "    Start: str = \"unknown\"\n",
    "    End: str = \"unknown\"\n",
    "    # Handlung_ausgeführt_von: Optional[str] = None\n",
    "    # Ort_der_Handlung: Optional[str] = None\n",
    "    # übertragenes_Objekt: Optional[str] = None\n",
    "    # empfänger: Optional[str] = None\n",
    "    # Art_des_Verhältnisses: Optional[str] = None\n",
    "    # Elternteil: Optional[str] = None\n",
    "\n",
    "    class Config:\n",
    "        extra = \"allow\"  # Allow extra fields\n",
    "\n",
    "\n",
    "\n",
    "parser_ner = PydanticOutputParser(pydantic_object=NEROutput)\n",
    "\n",
    "format_instructions_NER = parser_ner.get_format_instructions()\n",
    "print(format_instructions_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statement(BaseModel):\n",
    "    text: str = Field(description=\"An informative sentence extracted from the historical text.\")\n",
    "    ner_output: Optional[NEROutput] = None  # include NER output\n",
    "\n",
    "class StatementGroup(BaseModel):\n",
    "    date: str = Field(description=\"The date associated with the group of statements.\")\n",
    "    statements: List[Statement] = Field(description=\"A list of statements associated with the date.\")\n",
    "\n",
    "class AssistantOutput(BaseModel):\n",
    "    statement_groups: List[StatementGroup] = Field(description=\"A list of statement groups\")\n",
    "\n",
    "parser_statement_extraction = PydanticOutputParser(pydantic_object=AssistantOutput)\n",
    "\n",
    "\n",
    "format_instructions_statement_extraction = parser_statement_extraction.get_format_instructions()\n",
    "print(format_instructions_statement_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data/examples.json', 'r', encoding='utf-8') as file:\n",
    "    examples = json.load(file)\n",
    "\n",
    "system_msg = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a meticulous analyst with a focus on historical data. Your task is to process a provided historical record. For each given text please identify all statements that focus on the relationships and dependencies between entities in the given text, including biographical data. Also, structure the information, meaning:  Divide the text into two time based logical segments, each containing a self-contained piece of information (e.g., JJJJ-MM-TT, before JJJJ-MM-TT)\n",
    "Return the statements in german as simple sentences that allow for easy interpretation and reconstruction of the historical context. Each sentence must be informative in itself. Please ensure to include names in each sentence as demonstrated:\n",
    "John Doe goes to the store. John Doe buys apples.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example_user_msg = \"\"\"Please produce statements from the following text:\n",
    "{example_input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "example_assistant_msg = \"\"\"{example_output}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "user_msg = \"\"\"Please produce statements from the following text:\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "prompt_template_statement_extraction = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_msg),\n",
    "    \n",
    "    (\"user\", example_user_msg.replace(\"{example_input}\", \"{example_input_1}\")),\n",
    "    (\"assistant\", example_assistant_msg.replace(\"{example_output}\", \"{example_output_1}\")),\n",
    "    \n",
    "    (\"user\", example_user_msg.replace(\"{example_input}\", \"{example_input_2}\")),\n",
    "    (\"assistant\", example_assistant_msg.replace(\"{example_output}\", \"{example_output_2}\")),\n",
    "    \n",
    "    (\"user\", user_msg),\n",
    "])\n",
    "\n",
    "prompt_template_statement_extraction = prompt_template_statement_extraction.partial(format_instructions=format_instructions_statement_extraction)\n",
    "\n",
    "example_input_1 = examples[0][\"user_input\"]\n",
    "\n",
    "example_output_1 = examples[0][\"assistant_output_json\"]\n",
    "\n",
    "example_input_2 = examples[1][\"user_input\"]\n",
    "\n",
    "example_output_2 = examples[1][\"assistant_output_json\"]\n",
    "\n",
    "\n",
    "regeste = \"\"\"8652 1564 März 3, Prag.\n",
    "\n",
    "Erzherzog Ferdinand schenkt der edlen Philippina Welserin sonderlich ihres in Ehren und Tugend wohlverhaltens halben Schloss und Herrschaft Ambras samt allem Bau, Haus und Vorrat, das ihm sein Vater Kaiser Ferdinand I. geschenksweise überlassen habe.\n",
    "\n",
    "Geschehen und gegeben zu Prag den 3. Tag des Monats März nach Christi unseres Herrn Geburt im 1564.\n",
    "\n",
    "Eigenhändig unterschriebenes Originalpergament mit abgefallenem Siegel, Urkunden des Familienarchivs.\"\"\"\n",
    "\n",
    "variables_statement_extraction = {\n",
    "    \"example_input_1\": example_input_1,\n",
    "    \"example_output_1\": example_output_1,\n",
    "    \"example_input_2\": example_input_2,\n",
    "    \"example_output_2\": example_output_2,\n",
    "    \"question\": regeste,\n",
    "}\n",
    "\n",
    "statement_extraction_chain = prompt_template_statement_extraction | llm_TogehterAI_Llama3_70B_Lite | parser_statement_extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statement_extraction_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/examples_NER.json', 'r', encoding='utf-8') as file:\n",
    "    examples = json.load(file)\n",
    "\n",
    "system_msg = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a meticulous analyst with a focus on historical data. Your task is to produce a structured output for each given text.\n",
    "\n",
    "Your goal is to extract information about interactions, activities, relationships, and biographical details to enrich our prosopographical database.<|eot_id|><|start_header_id|>user<|end_header_id|>\"\"\"\n",
    "\n",
    "example_user_msg = \"\"\"Please produce a structured output describing the action from the following text:\n",
    "{example_input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "example_assistant_msg = \"\"\"{example_output}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "user_msg = \"\"\"\n",
    "\n",
    "Please produce a structured output describing the action from the following text:\n",
    "{statement}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_NER = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_msg),\n",
    "    \n",
    "    (\"user\", example_user_msg.replace(\"{example_input}\", \"{example_input_1}\")),\n",
    "    (\"assistant\", example_assistant_msg.replace(\"{example_output}\", \"{example_output_1}\")),\n",
    "    \n",
    "    (\"user\", example_user_msg.replace(\"{example_input}\", \"{example_input_2}\")),\n",
    "    (\"assistant\", example_assistant_msg.replace(\"{example_output}\", \"{example_output_2}\")),\n",
    "    \n",
    "    (\"user\", user_msg),\n",
    "])\n",
    "\n",
    "prompt_template_NER = prompt_template_NER.partial(format_instructions=format_instructions_NER)\n",
    "\n",
    "example_input_1 = examples[0][\"user_input\"]\n",
    "\n",
    "example_output_1 = examples[0][\"assistant_output_json\"]\n",
    "\n",
    "example_input_2 = examples[1][\"user_input\"]\n",
    "\n",
    "example_output_2 = examples[1][\"assistant_output_json\"]\n",
    "\n",
    "chain_NER = prompt_template_NER | llm_TogehterAI_Llama3_8B | parser_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RunnableLambda to process statements and attach NER outputs\n",
    "def process_statements_with_NER(result_dict):\n",
    "    for statement_group in result_dict.statement_groups:\n",
    "        for statement in statement_group.statements:\n",
    "            # Create a dictionary for each statement\n",
    "            statement_variables = {\n",
    "                \"example_input_1\": example_input_1,\n",
    "                \"example_output_1\": example_output_1,\n",
    "                \"example_input_2\": example_input_2,\n",
    "                \"example_output_2\": example_output_2,\n",
    "                \"statement\": statement.text,\n",
    "            }\n",
    "            # Run chain_NER on the statement\n",
    "            ner_output = chain_NER.invoke(statement_variables)\n",
    "            # Assign the NER output to the statement's 'ner_output' key\n",
    "            statement.ner_output = ner_output\n",
    "    return result_dict  # This is now a dict that can be converted to JSON\n",
    "\n",
    "# Create the RunnableLambda\n",
    "runnable_process_statements = RunnableLambda(process_statements_with_NER)\n",
    "\n",
    "# Combine the chains into a final chain\n",
    "final_chain = statement_extraction_chain | runnable_process_statements\n",
    "\n",
    "\n",
    "# Invoke the final chain with the initial variables\n",
    "result = final_chain.invoke(variables_statement_extraction)\n",
    "\n",
    "# Print the final output\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = result.dict()\n",
    "\n",
    "json_output = json.dumps(result_dict, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(json_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
